{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14343173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 17:04:49.720505: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-05 17:04:49.720543: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# model building\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Flatten\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dropout\n",
    "from keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# URL Download\n",
    "import csv\n",
    "import io\n",
    "import urllib.request\n",
    "import requests\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112913ea",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa3630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Read in the most recent bike theft data from Polizei Berlin and return\n",
    "    a pandas dataframe \"\"\"\n",
    "    url = \"https://www.internetwache-polizei-berlin.de/vdb/Fahrraddiebstahl.csv\"\n",
    "    download = requests.get(url)\n",
    "    decoded_content = download.content.decode('ISO-8859-1')\n",
    "    file = decoded_content.splitlines()\n",
    "\n",
    "    cr = csv.DictReader(file, delimiter=',')\n",
    "    my_list = list(cr)\n",
    "    df  = pd.DataFrame(my_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4abda333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_col_names(d):\n",
    "    eng_col_names = {\n",
    "        \"ANGELEGT_AM\": \"date_reported\",\n",
    "        \"TATZEIT_ANFANG_DATUM\": \"date_theft_start\",\n",
    "        \"TATZEIT_ANFANG_STUNDE\": \"hour_theft_start\",\n",
    "        \"TATZEIT_ENDE_DATUM\": \"date_theft_end\",\n",
    "        \"TATZEIT_ENDE_STUNDE\": \"hour_theft_end\",\n",
    "        \"LOR\": \"LOR\",\n",
    "        \"SCHADENSHOEHE\": \"estimated_value\",\n",
    "        \"VERSUCH\": \"attempt\",\n",
    "        \"ART_DES_FAHRRADS\": \"type_bike\",\n",
    "        \"DELIKT\": \"theft_type\",\n",
    "        \"ERFASSUNGSGRUND\": \"theft_type_detail\"\n",
    "    }\n",
    "    d.rename(columns= eng_col_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4460c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for renaming the categories\n",
    "def rename_type_bike(x):\n",
    "    \"\"\"translation of the categories of variable \"type_bike\".\n",
    "    \"\"\"\n",
    "    if x == \"Herrenfahrrad\":\n",
    "        return \"man's bike\"\n",
    "    if x == \"Damenfahrrad\":\n",
    "        return \"woman's bike\"\n",
    "    if x == \"Fahrrad\":\n",
    "        return \"bike\"\n",
    "    if x == \"Kinderfahrrad\":\n",
    "        return \"child's bike\"\n",
    "    else:\n",
    "        return \"other bike\"\n",
    "\n",
    "# dictionary for \"attempt\"\n",
    "attempt_dict = {\n",
    "    \"Ja\": \"Yes\",\n",
    "    \"Nein\": \"No\",\n",
    "    \"Unbekannt\": \"Unknown\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed8adb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates translation of column and category names,\n",
    "#  conversion of dtypes, drop duplicates and create\n",
    "#  higher regional levels from LOR\n",
    "def clean_theft_data(d):\n",
    "    \"\"\"Takes in the pd Dataframe created in load_data() and\n",
    "    returns a clean dataframe\"\"\"\n",
    "    #translate columns to English\n",
    "    translate_col_names(d)\n",
    "\n",
    "    #translate bike type to English\n",
    "    d[\"type_bike\"] = d[\"type_bike\"].apply(rename_type_bike)\n",
    "\n",
    "    #translate attempt type to English\n",
    "    d[\"attempt\"] = d[\"attempt\"].map(attempt_dict)\n",
    "\n",
    "    # convert the date columns to format='%d.%m.%Y\n",
    "    d[\"date_reported\"] = pd.to_datetime(d[\"date_reported\"], format='%d.%m.%Y')\n",
    "    d[\"date_theft_start\"] = pd.to_datetime(d[\"date_theft_start\"], format='%d.%m.%Y')\n",
    "    d[\"date_theft_end\"] = pd.to_datetime(d[\"date_theft_end\"], format='%d.%m.%Y')\n",
    "\n",
    "    # convert the time columns to int\n",
    "    d[\"hour_theft_start\"] = d[\"hour_theft_start\"].astype(int)\n",
    "    d[\"hour_theft_end\"] = d[\"hour_theft_end\"].astype(int)\n",
    "\n",
    "    #convert value column to float\n",
    "    d[\"estimated_value\"] = d[\"estimated_value\"].astype(float)\n",
    "\n",
    "    #drop duplicates\n",
    "    d = d.drop_duplicates()\n",
    "\n",
    "    # BZR (first six numbers)\n",
    "    d[\"BZR\"] = d[\"LOR\"].str[:6]\n",
    "\n",
    "    # PGR (first four numbers)\n",
    "    d[\"PGR\"] = d[\"LOR\"].str[:4]\n",
    "\n",
    "    # Bezirk (first four numbers)\n",
    "    d[\"Bezirk\"] = d[\"LOR\"].str[:2]\n",
    "\n",
    "    return d\n",
    "\n",
    "# Group by bezirk and sum up\n",
    "def pivot_theft_data(d):\n",
    "    \"\"\"Groups dataframe by Bezirk and returns sum of thefts for\n",
    "    each Bezirk and day (date_reported)\"\"\"\n",
    "    d = d.pivot_table(index = \"date_reported\", columns = \"Bezirk\", values = \"type_bike\", aggfunc= \"count\")\n",
    "    d.fillna(value = 0, inplace=True)\n",
    "    return d\n",
    "\n",
    "\n",
    "# Calculate percentage theft by Bezirk\n",
    "def perc_split_bezirk(d):\n",
    "    \"\"\"returns df showing % split of bikes stolen over the last 2 weeks per Bezirk in Berlin\"\"\"\n",
    "    d = d[-15:]\n",
    "    d.loc['perc_split']= d.sum()\n",
    "    d = d.div(d.sum(axis=1), axis=0)\n",
    "    d = d.iloc[-1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "\n",
    "# Calculate rolling average\n",
    "def calculate_rolling_average(df, window_size):\n",
    "    \"\"\"Calculate rolling average over the last window_size days.\n",
    "    Fills missing values with mean of the last window_size days\"\"\"\n",
    "    fill_value = df[\"total\"][-window_size:].mean()\n",
    "    df[\"total_moving_average\"] = df[\"total\"].rolling(window = window_size, center = False).mean().fillna(fill_value)\n",
    "\n",
    "# Calculate the total number of reported stolen bikes in the last 365 days\n",
    "def bikes_stolen_365():\n",
    "    \"\"\"returns total bikes reported stolen in the last 365 days in Berlin\"\"\"\n",
    "    df = load_data()\n",
    "    df = clean_theft_data(df)\n",
    "    df = pivot_theft_data(df)\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    df = pd.DataFrame(df[\"Total\"])\n",
    "    df =df[-365:]\n",
    "    total_stolen_365=df.sum().values[0]\n",
    "    return int(total_stolen_365)\n",
    "\n",
    "# Calculates \"Every XX minutes a bike is reported as stolen in Berlin\"\n",
    "def theft_frequency():\n",
    "    \"\"\"returns frequency (in minutes) of bikes being reported as\n",
    "    stolen in Berlin in the last 365 days\"\"\"\n",
    "    minutes_day=1440\n",
    "    minutes_year=1440*365\n",
    "    return round(minutes_year/bikes_stolen_365())\n",
    "\n",
    "\n",
    "# Create the dataframe for the modelling\n",
    "def create_modelling_dataframe():\n",
    "    \"\"\"Read in most recent dataset from URL, clean it, group it\n",
    "    and return dataframe for model creation\n",
    "    \"\"\"\n",
    "    # load data\n",
    "    df = load_data()\n",
    "    # clean data\n",
    "    df= clean_theft_data(df)\n",
    "    # group data by Bezirk and date_reported and sum up\n",
    "    df = pivot_theft_data(df)\n",
    "\n",
    "    # add \"total column\"\n",
    "    df[\"total\"] = df.sum(axis = 1)\n",
    "\n",
    "    # cut-off the last three days\n",
    "    # df.drop(df.tail(3).index,inplace=True)\n",
    "\n",
    "    # calculate rolling average\n",
    "    calculate_rolling_average(df, window_size = 3)\n",
    "\n",
    "    # select relevant columns for modelling\n",
    "    cols_list =  [\"total\", \"total_moving_average\"]\n",
    "    df = df[cols_list]\n",
    "\n",
    "    return df\n",
    "\n",
    "# calculates the mean estimated value of all reported stolen bikes\n",
    "def mean_estimated_value():\n",
    "    \"\"\"Returns the mean of \"estimated value\" of all stolen bikes.\n",
    "    \"Kellereinbruch\" is filtered out\n",
    "    \"\"\"\n",
    "    df = load_data()\n",
    "    df= clean_theft_data(df)\n",
    "    start_date = datetime.datetime.today() - datetime.timedelta(365)\n",
    "    cond = np.logical_and(df[\"theft_type\"] != \"Keller- und Bodeneinbruch\", df[\"date_reported\"] >= start_date)\n",
    "    df = df[cond]\n",
    "    return round(df.estimated_value.mean())\n",
    "\n",
    "\n",
    "def hourly_count_stolen_bikes():\n",
    "    \"\"\"Creates a line plot of the number of stolen bikes by hour_theft_start\n",
    "    \"\"\"\n",
    "\n",
    "    df = load_data()\n",
    "    df = clean_theft_data(df)\n",
    "\n",
    "    count_per_hour = df.groupby(\"hour_theft_start\").count()\n",
    "    count_per_hour = count_per_hour[[\"date_reported\"]].reset_index()\n",
    "    count_per_hour[\"count_stolen\"] = count_per_hour[\"date_reported\"]\n",
    "    fig = px.line(count_per_hour, x='hour_theft_start', y='count_stolen',\n",
    "                title='Berlin: Hourly count of stolen bikes from 2021-01-01',\n",
    "                labels={\"hour_theft_start\": \"Assumed hour of theft\", \"count_stolen\": \"Number of stolen bikes\"})\n",
    "\n",
    "    return fig\n",
    "\n",
    "def get_last_date():\n",
    "    df = load_data()\n",
    "    df[\"date_reported\"] = pd.to_datetime(df[\"ANGELEGT_AM\"], format='%d.%m.%Y')\n",
    "    last_date = df[\"date_reported\"].max().date()\n",
    "    return last_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1eb859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opt_model():\n",
    "    \"\"\"\n",
    "    Creates the finetuned model selected in B_Theft_Modelling\n",
    "    Outputs models, that needs to be compiled and fit\"\"\"\n",
    "    model = Sequential()\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(units = 70, activation = \"tanh\", return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # second LSTM layer\n",
    "    model.add(LSTM(units= 30, activation= \"tanh\", return_sequences= False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # output layer to predict one value\n",
    "    model.add(Dense(1, activation= \"linear\"))\n",
    "    return model\n",
    "\n",
    "def get_X_y(dataset, window_size, future_horizon):\n",
    "    \"\"\"Creates arrays to be fed into the RNN model\n",
    "    Input: dataframe after create_modelling_dataframe, window_size and future_horizon\n",
    "    Output: Arrays for X and y\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(0, dataset.shape[0] - window_size - future_horizon):\n",
    "        X.append(dataset[i: i + window_size])\n",
    "        y.append(dataset[\"total\"][i + window_size: i + window_size + future_horizon])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # expand dimensions\n",
    "    #X = np.expand_dims(X, 2)\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e148d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7263e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "480dc938",
   "metadata": {},
   "source": [
    "# Read in data from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3867493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1609/2723451935.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[\"BZR\"] = d[\"LOR\"].str[:6]\n",
      "/tmp/ipykernel_1609/2723451935.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[\"PGR\"] = d[\"LOR\"].str[:4]\n",
      "/tmp/ipykernel_1609/2723451935.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[\"Bezirk\"] = d[\"LOR\"].str[:2]\n"
     ]
    }
   ],
   "source": [
    "df = create_modelling_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c695423f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Bezirk</th>\n",
       "      <th>total</th>\n",
       "      <th>total_moving_average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_reported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>4.0</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>7.0</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-03</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-04</th>\n",
       "      <td>21.0</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>31.0</td>\n",
       "      <td>18.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Bezirk         total  total_moving_average\n",
       "date_reported                             \n",
       "2021-01-01       4.0             44.000000\n",
       "2021-01-02       7.0             44.000000\n",
       "2021-01-03       3.0              4.666667\n",
       "2021-01-04      21.0             10.333333\n",
       "2021-01-05      31.0             18.333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5bdf5",
   "metadata": {},
   "source": [
    "# Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78105bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b13ba2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ = int(len(df)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb7f0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:len_]\n",
    "df_test = df[len_:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6154dde8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dbb5146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73a14934",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y(df_train, 31, 1)\n",
    "X_test, y_test = get_X_y(df_test, 31, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f8045",
   "metadata": {},
   "source": [
    "# Baseline model (last observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7919b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_base = X_test[:,-1,0]\n",
    "y_pred_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e0656fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd38a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22524cd6",
   "metadata": {},
   "source": [
    "# Create empty model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35bb02f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 17:23:05.367109: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-05 17:23:05.367147: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-05 17:23:05.367164: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-C0GM00LC): /proc/driver/nvidia/version does not exist\n",
      "2022-04-05 17:23:05.367947: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = create_opt_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcda762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = callbacks.EarlyStopping(patience = 5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c15d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e31721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f978a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f187c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = create_opt_model()\n",
    "    model.compile(loss = \"mse\",\n",
    "                  optimizer = \"adam\",\n",
    "                  metrics = \"mean_absolute_percentage_error\")\n",
    "\n",
    "    print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
